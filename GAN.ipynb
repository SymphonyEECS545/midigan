{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all cells in order and read comments to understand what happens exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dem Libraries!\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To get the sine waves data\n",
    "# n_samples : Number of sine waves you want generated\n",
    "def sample_data(n_samples=10000, x_vals=np.arange(0, 5, .1), max_offset=100, mul_range=[1, 2]):\n",
    "    vectors = []\n",
    "    for i in range(n_samples):\n",
    "        offset = np.random.random() * max_offset\n",
    "#         print(\"Offset\",offset)\n",
    "        mul = mul_range[0] + np.random.random() * (mul_range[1] - mul_range[0])\n",
    "#         print(\"Mul\",mul)\n",
    "        vectors.append(\n",
    "            np.sin(offset + x_vals * mul) / 2 + .5\n",
    "        )\n",
    "    return np.array(vectors)\n",
    "\n",
    "#Plot 5 sine waves as a test to visually check if it works\n",
    "ax = pd.DataFrame(np.transpose(sample_data(5))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generator Model :\n",
    "# Needs to be able to take in random noise and generate realistic looking output data\n",
    "\n",
    "def get_generative(G_in, dense_dim=200, out_dim=50, lr=1e-3):\n",
    "    x = Dense(dense_dim)(G_in)\n",
    "    x = Activation('tanh')(x)\n",
    "    G_out = Dense(out_dim, activation='tanh')(x)\n",
    "    G = Model(G_in, G_out)\n",
    "    opt = SGD(lr=lr)\n",
    "    G.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return G, G_out\n",
    "\n",
    "G_in = Input(shape=[10])\n",
    "G, G_out = get_generative(G_in)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Discriminator Model :\n",
    "# Needs to be able to take in a generated signal and distinguish between real and fake(generated)\n",
    "\n",
    "def get_discriminative(D_in, lr=1e-3, drate=.25, n_channels=50, conv_sz=5, leak=.2):\n",
    "    x = Reshape((-1, 1))(D_in)\n",
    "    \n",
    "    x = Conv1D(n_channels, conv_sz, activation='relu')(x)\n",
    "    x = Dropout(drate)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(n_channels)(x)\n",
    "    D_out = Dense(2, activation='sigmoid')(x)\n",
    "    D = Model(D_in, D_out)\n",
    "    dopt = Adam(lr=lr)\n",
    "    D.compile(loss='binary_crossentropy', optimizer=dopt)\n",
    "    return D, D_out\n",
    "\n",
    "D_in = Input(shape=[50])\n",
    "D, D_out = get_discriminative(D_in)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to make sure the Discriminators weights are frozen, while training the Generator\n",
    "def set_trainability(model, trainable=False):\n",
    "    model.trainable = trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "        \n",
    "def make_gan(GAN_in, G, D):\n",
    "    set_trainability(D, False)\n",
    "    x = G(GAN_in)\n",
    "    GAN_out = D(x)\n",
    "    GAN = Model(GAN_in, GAN_out)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=G.optimizer)\n",
    "    return GAN, GAN_out\n",
    "\n",
    "GAN_in = Input([10])\n",
    "GAN, GAN_out = make_gan(GAN_in, G, D)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get a concatenated input of real_data and fake_data with appropriate concatenated labels\n",
    "def sample_data_and_gen(G, noise_dim=10, n_samples=10000):\n",
    "    # Generated Real Samples \n",
    "    XT = sample_data(n_samples=n_samples)\n",
    "    # Get the random noise that'll be used to generate the fake data\n",
    "    XN_noise = np.random.uniform(0, 1, size=[n_samples, noise_dim])\n",
    "    # Generate the Fake Samples\n",
    "    XN = G.predict(XN_noise)\n",
    "    # Concatenat the Real and Fake Data\n",
    "    X = np.concatenate((XT, XN))\n",
    "    # Concatenate the labels and set the appropriate values\n",
    "    y = np.zeros((2*n_samples, 2))\n",
    "    y[:n_samples, 1] = 1\n",
    "    y[n_samples:, 0] = 1\n",
    "    return X, y\n",
    "\n",
    "def pretrain(G, D, noise_dim=10, n_samples=10000, batch_size=32):\n",
    "    # Get the real samples for the pretraining of the discriminator\n",
    "    X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "    # Allow the Discriminator to be trained\n",
    "    set_trainability(D, True)\n",
    "    # Fit the Discriminator with 1 epoch\n",
    "    D.fit(X, y, epochs=1, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform One Train run for the Determiner\n",
    "pretrain(G, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get sample noise for the GAN training cycle\n",
    "def sample_noise(G, noise_dim=10, n_samples=10000):\n",
    "    X = np.random.uniform(0, 1, size=[n_samples, noise_dim])\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 1] = 1\n",
    "    return X, y\n",
    "\n",
    "# Training the GAN by backpropagating the losses of the discriminator on the generated samples, \n",
    "# whilst freezing discriminator weights\n",
    "\n",
    "def train(GAN, G, D, epochs=500, n_samples=10000, noise_dim=10, batch_size=32, verbose=False, v_freq=50):\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    e_range = range(epochs)\n",
    "    if verbose:\n",
    "        e_range = tqdm(e_range)\n",
    "    #For each EPOCH\n",
    "    for epoch in e_range:\n",
    "        # Get True and Generated Samples with Labels\n",
    "        X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        # Allow Discriminator to be Trained\n",
    "        set_trainability(D, True)\n",
    "        # Evaluate the Discriminator loss on this set(only to record loss)\n",
    "        d_loss.append(D.train_on_batch(X, y))\n",
    "        \n",
    "        # Now just get the generated samples\n",
    "        X, y = sample_noise(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        # Freeze the Discriminator Weights\n",
    "        set_trainability(D, False)\n",
    "        # Evaluate the Generator loss on this set\n",
    "        g_loss.append(GAN.train_on_batch(X, y))\n",
    "        if verbose and (epoch + 1) % v_freq == 0:\n",
    "            print(\"Epoch #{}: Generative Loss: {}, Discriminative Loss: {}\".format(epoch + 1, g_loss[-1], d_loss[-1]))\n",
    "    return d_loss, g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_loss, g_loss = train(GAN, G, D, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_VIEWED_SAMPLES = 2\n",
    "data_and_gen, _ = sample_data_and_gen(G, n_samples=N_VIEWED_SAMPLES)\n",
    "\n",
    "#To View the Generated Output\n",
    "pd.DataFrame(np.transpose(data_and_gen[N_VIEWED_SAMPLES:])).plot()\n",
    "#To View a smoothened version of the Generated Output(using a rollling mean)\n",
    "#pd.DataFrame(np.transpose(data_and_gen[N_VIEWED_SAMPLES:])).rolling(5).mean()[5:].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Generative Loss': g_loss,\n",
    "        'Discriminative Loss': d_loss,\n",
    "    }\n",
    ").plot(title='Training loss', logy=True)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code following this is for playing around to understand how the MidiGan dataset is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instru = open('./trial/instruments.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.load('./trial/arrays.npz',mmap_mode='r')\n",
    "on_roll = np.load('./trial/onset_rolls.npz',mmap_mode='r')\n",
    "pi_roll = np.load('./trial/piano_rolls.npz',mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To access the name of the Piano Roll files\n",
    "pi_roll.files\n",
    "\n",
    "# Once you get the name of the argument you wish to see, \n",
    "pi_roll['name of the argurment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr['downbeat_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./trial/instruments.json') as f:\n",
    "    datastore = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pi_roll['0_csc_indptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['0_csc_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pi_roll['0_csc_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['2_csc_indptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['0_csc_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(pi_roll['11_csc_indptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(pi_roll['10_csc_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['11_csc_indptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['6_csc_indptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['5_csc_indptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['5_csc_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['6_csc_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['5_csc_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['6_csc_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr['downbeat_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_roll['0_csc_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piano_notes = np.zeros((11520,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
