{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dem Libraries!\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "import pretty_midi\n",
    "\n",
    "#Paths\n",
    "training_path = './Training Stage 1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To get the sine waves data\n",
    "# n_samples : Number of sine waves you want generated\n",
    "def sample_data(training_path):\n",
    "    training_path = './Training Stage 1/'\n",
    "    filenames = []\n",
    "    lens = []\n",
    "    fin_midi_stream = []\n",
    "    for filename in os.listdir(training_path):\n",
    "        filenames.append(os.path.join(training_path,filename))\n",
    "    fin_midi_streama = []\n",
    "    fin_midi_files = []\n",
    "    for file in filenames:\n",
    "        temp = pretty_midi.PrettyMIDI(file)\n",
    "        melody = temp.instruments[0]\n",
    "    #     chord = temp.instruments[1]\n",
    "        melody_math = melody.get_piano_roll(16)\n",
    "        curr_stream = np.argmax(melody_math, axis=0)\n",
    "        fin_midi_streama.extend(curr_stream)\n",
    "    chop_size = 256\n",
    "    num_of_chops = len(fin_midi_streama)//chop_size\n",
    "    for i in range(num_of_chops):\n",
    "        fin_midi_files.append(fin_midi_streama[(i)*chop_size:(i+1)*chop_size])\n",
    "    \n",
    "    return fin_midi_files\n",
    "\n",
    "ALL_DATA = sample_data(training_path)\n",
    "\n",
    "def get_ALL_data(n_samples):\n",
    "    return ALL_DATA[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generator Model :\n",
    "# Needs to be able to take in random noise and generate realistic looking output data\n",
    "\n",
    "def get_generative(G_in, dense_dim=400, out_dim=256, lr=1e-3):\n",
    "    x = Dense(dense_dim)(G_in)\n",
    "    x = Activation('tanh')(x)\n",
    "    G_out = Dense(out_dim, activation='tanh')(x)\n",
    "    G = Model(G_in, G_out)\n",
    "    opt = SGD(lr=lr)\n",
    "    G.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return G, G_out\n",
    "\n",
    "G_in = Input(shape=[16])\n",
    "G, G_out = get_generative(G_in)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Discriminator Model :\n",
    "# Needs to be able to take in a generated signal and distinguish between real and fake(generated)\n",
    "\n",
    "def get_discriminative(D_in, lr=1e-3, drate=.25, n_channels=50, conv_sz=5, leak=.2):\n",
    "    x = Reshape((-1, 1))(D_in)\n",
    "    \n",
    "    x = Conv1D(n_channels, conv_sz, activation='relu')(x)\n",
    "    x = Dropout(drate)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(n_channels)(x)\n",
    "    D_out = Dense(2, activation='sigmoid')(x)\n",
    "    D = Model(D_in, D_out)\n",
    "    dopt = Adam(lr=lr)\n",
    "    D.compile(loss='binary_crossentropy', optimizer=dopt)\n",
    "    return D, D_out\n",
    "\n",
    "D_in = Input(shape=[256])\n",
    "D, D_out = get_discriminative(D_in)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to make sure the Discriminators weights are frozen, while training the Generator\n",
    "def set_trainability(model, trainable=False):\n",
    "    model.trainable = trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "        \n",
    "def make_gan(GAN_in, G, D):\n",
    "    set_trainability(D, False)\n",
    "    x = G(GAN_in)\n",
    "    GAN_out = D(x)\n",
    "    GAN = Model(GAN_in, GAN_out)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=G.optimizer)\n",
    "    return GAN, GAN_out\n",
    "\n",
    "GAN_in = Input([16])\n",
    "GAN, GAN_out = make_gan(GAN_in, G, D)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to get a concatenated input of real_data and fake_data with appropriate concatenated labels\n",
    "def sample_data_and_gen(G, noise_dim=16, n_samples=15000):\n",
    "    # Generated Real Samples \n",
    "    XT = get_ALL_data(n_samples)\n",
    "    # Get the random noise that'll be used to generate the fake data\n",
    "    XN_noise = np.random.uniform(73, 87, size=[n_samples, noise_dim])\n",
    "    # Generate the Fake Samples\n",
    "    XN = G.predict(XN_noise)\n",
    "    # Concatenat the Real and Fake Data\n",
    "    X = np.concatenate((XT, XN))\n",
    "    # Concatenate the labels and set the appropriate values\n",
    "    y = np.zeros((2*n_samples, 2))\n",
    "    y[:n_samples, 1] = 1\n",
    "    y[n_samples:, 0] = 1\n",
    "    return X, y\n",
    "\n",
    "def pretrain(G, D, noise_dim=16, n_samples=15000, batch_size=32):\n",
    "    # Get the real samples for the pretraining of the discriminator\n",
    "    X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "    # Allow the Discriminator to be trained\n",
    "    set_trainability(D, True)\n",
    "    # Fit the Discriminator with 1 epoch\n",
    "    D.fit(X, y, epochs=1, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform One Train run for the Determiner\n",
    "pretrain(G, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get sample noise for the GAN training cycle\n",
    "def sample_noise(G, noise_dim=16, n_samples=15000):\n",
    "    X = np.random.uniform(73, 87, size=[n_samples, noise_dim])\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 1] = 1\n",
    "    return X, y\n",
    "\n",
    "# Training the GAN by backpropagating the losses of the discriminator on the generated samples, \n",
    "# whilst freezing discriminator weights\n",
    "\n",
    "def train(GAN, G, D, epochs=50, n_samples=15000, noise_dim=16, batch_size=32, verbose=False, v_freq=5):\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    e_range = range(epochs)\n",
    "    if verbose:\n",
    "        e_range = tqdm(e_range)\n",
    "    #For each EPOCH\n",
    "    for epoch in e_range:\n",
    "        # Get True and Generated Samples with Labels\n",
    "        X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        # Allow Discriminator to be Trained\n",
    "        set_trainability(D, True)\n",
    "        # Evaluate the Discriminator loss on this set(only to record loss)\n",
    "        d_loss.append(D.train_on_batch(X, y))\n",
    "        \n",
    "        # Now just get the generated samples\n",
    "        X, y = sample_noise(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        # Freeze the Discriminator Weights\n",
    "        set_trainability(D, False)\n",
    "        # Evaluate the Generator loss on this set\n",
    "        g_loss.append(GAN.train_on_batch(X, y))\n",
    "        if verbose and (epoch + 1) % v_freq == 0:\n",
    "            print(\"Epoch #{}: Generative Loss: {}, Discriminative Loss: {}\".format(epoch + 1, g_loss[-1], d_loss[-1]))\n",
    "    return d_loss, g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_loss, g_loss = train(GAN, G, D, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This step is not applicable here for now. \n",
    "\n",
    "# N_VIEWED_SAMPLES = 2\n",
    "# data_and_gen, _ = sample_data_and_gen(G, n_samples=N_VIEWED_SAMPLES)\n",
    "\n",
    "# #To View the Generated Output\n",
    "# pd.DataFrame(np.transpose(data_and_gen[N_VIEWED_SAMPLES:])).plot()\n",
    "# #To View a smoothened version of the Generated Output(using a rollling mean)\n",
    "# #pd.DataFrame(np.transpose(data_and_gen[N_VIEWED_SAMPLES:])).rolling(5).mean()[5:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shreyans is a fucking asshole. Dipshit lil bitch. \n",
    "def fuck_shrey(d):\n",
    "    d = np.round(d).astype(int)\n",
    "    j = np.zeros((128,np.shape(d)[1]))\n",
    "    i=0\n",
    "    while (i<np.shape(d)[1]):\n",
    "        j[d[0,i],i] = 1\n",
    "        i = i+1\n",
    "    return j\n",
    "\n",
    "def pianoroll_to_midi(piano_roll, fs=16, program=0):\n",
    "    '''Converts a Piano Roll array to a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    \n",
    "    Input:\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    \n",
    "    Returns:\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    period=1./fs\n",
    "    \n",
    "    notes, frames = piano_roll.shape #get number of frames in our piano roll\n",
    "    pm = pretty_midi.PrettyMIDI() #create a Pretty Midi object\n",
    "    instrument = pretty_midi.Instrument(program=0) #specify our instrument\n",
    "\n",
    "    #record previous pitch/velocity so we can concatenate notes together\n",
    "    prev_pitch=0\n",
    "    prev_velocity=0\n",
    "    notelength=0\n",
    "    starttime=0\n",
    "    endtime=period\n",
    "    \n",
    "    i=0\n",
    "    while i<frames: #range over the frames of the piano roll\n",
    "\n",
    "        #need to specify velocity (100 for note, 0 for rest),  start time, end time, and pitch\n",
    "        \n",
    "        \n",
    "        #for ith column of piano roll get the (possible) non-zero index which\n",
    "        #corresponds to the pitch\n",
    "        col=piano_roll[:,i] \n",
    "        colnext=piano_roll[:,i+1]\n",
    "        tmp=np.nonzero(col)\n",
    "        tmpnext=np.nonzero(colnext)\n",
    "        \n",
    "        if tmp[0].size==0: #current is rest note, don't need to worry about length\n",
    "            \n",
    "            velocity=0\n",
    "            starttime=i*period\n",
    "            endtime=period+i*period\n",
    "            current_pitch=0\n",
    "           \n",
    "        \n",
    "        else:\n",
    "            #get current pitch and set the start time\n",
    "            velocity=100\n",
    "            current_pitch=tmp[0][0]\n",
    "            starttime=i*period\n",
    "            \n",
    "            \n",
    "            #loop over future notes to find when pitch changes\n",
    "            pitchchange=False\n",
    "            while pitchchange==False:\n",
    "                \n",
    "                #if end of song quit\n",
    "                if i==frames-1:\n",
    "                    endtime=period+i*period\n",
    "                    break\n",
    "                    \n",
    "                #get next note\n",
    "                colnext=piano_roll[:,i+1]\n",
    "                tmpnext=np.nonzero(colnext)\n",
    "                \n",
    "                #if next note is a rest\n",
    "                if tmpnext[0].size==0: \n",
    "                    endtime=period+i*period\n",
    "                    break\n",
    "                    \n",
    "                #if next frame has different pitch\n",
    "                elif tmpnext[0][0]!=current_pitch: \n",
    "                    endtime=period+i*period\n",
    "                    pitchchange=True\n",
    "            \n",
    "                else:\n",
    "                    #increment to next frame\n",
    "                    i=i+1\n",
    "                    \n",
    "            \n",
    "        pm_note=pretty_midi.Note(velocity=100, pitch=current_pitch, start=starttime, end=endtime)\n",
    "        i=i+1\n",
    "        #we have appended note, now move to next note   \n",
    "        instrument.notes.append(pm_note)\n",
    "        #print starttime\n",
    "        #print endtime\n",
    "        \n",
    "    pm.instruments.append(instrument)\n",
    "\n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating the tune and writing to file\n",
    "def generate_tune(gan_output):\n",
    "    form = np.zeros((128,len(gan_output)))\n",
    "    for i in range(len(gan_output)):\n",
    "        form[int(gan_output[i])][i]=60\n",
    "    form_midi = pianoroll_to_midi(form,16,0)\n",
    "    form_midi.write('AI_Tune.mid')\n",
    "    return form_midi\n",
    "\n",
    "# Make Music Function\n",
    "def make_music(dble_octvs):\n",
    "    xyz, _ = sample_data_and_gen(G, n_samples=10)\n",
    "    xyz_concat = []\n",
    "    for sixteen_notes in xyz:\n",
    "        xyz_concat.extend(sixteen_notes)\n",
    "    generate_tune(xyz_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many double octaves(16 notes) are to be generated?\n",
    "double_octaves = 10\n",
    "make_music(double_octaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
